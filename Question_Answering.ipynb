{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Question Answering.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFLxONaL9irv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential, Model,load_model\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.layers import Input, Activation, Dense, Permute, Dropout, merge\n",
        "from keras.layers import LSTM, GRU\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils.data_utils import get_file\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras import backend as K\n",
        "\n",
        "from functools import reduce\n",
        "import tarfile\n",
        "import numpy as np\n",
        "import re\n",
        "\n",
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agKYBlYUzEvu",
        "colab_type": "code",
        "outputId": "4e874b03-8e1a-4c38-e876-870c206a6c18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "try:\n",
        "    path = get_file('babi-tasks-v1-2.tar.gz', origin='https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz')\n",
        "except:\n",
        "    print('Error downloading dataset, please download it manually:\\n'\n",
        "          '$ wget http://www.thespermwhale.com/jaseweston/babi/tasks_1-20_v1-2.tar.gz\\n'\n",
        "          '$ mv tasks_1-20_v1-2.tar.gz ~/.keras/datasets/babi-tasks-v1-2.tar.gz')\n",
        "    raise\n",
        "tar = tarfile.open(path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/babi_tasks_1-20_v1-2.tar.gz\n",
            "11747328/11745123 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9iuyFCP9TA8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(sent):\n",
        "    return [ x.strip() for x in re.split('(\\W+)?', sent) if x.strip()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikgkHOsO-Fng",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_stories(lines, only_supporting=False):\n",
        "  data=[]\n",
        "  story = []\n",
        "  for line in lines:\n",
        "        line = line.decode('utf-8').strip()\n",
        "        nid, line = line.split(' ', 1)\n",
        "        nid = int(nid)\n",
        "        if nid == 1:\n",
        "            story = []\n",
        "        if '\\t' in line:\n",
        "            q, a, supporting = line.split('\\t')\n",
        "            q = tokenize(q)\n",
        "            substory = None\n",
        "            if only_supporting:\n",
        "                # Only select the related substory\n",
        "                supporting = map(int, supporting.split())\n",
        "                substory = [story[i - 1] for i in supporting]\n",
        "            else:\n",
        "                # Provide all the substories\n",
        "                substory = [x for x in story if x]\n",
        "            data.append((substory, q, a))\n",
        "            story.append('')\n",
        "        else:\n",
        "            sent = tokenize(line)\n",
        "            story.append(sent)\n",
        "  return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PJdgr6rC89h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_stories(f, only_supporting=False, max_length=None):\n",
        "    data = parse_stories(f.readlines(), only_supporting=only_supporting)\n",
        "    flatten = lambda data: reduce(lambda x, y: x + y, data)\n",
        "    data = [(flatten(story), q, answer) for story, q, answer in data if not max_length or len(flatten(story)) < max_length]\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w32sI6w9DH-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vectorize_stories(data, word_idx, story_maxlen, query_maxlen):\n",
        "    X = []\n",
        "    Xq = []\n",
        "    Y = []\n",
        "    for story, query, answer in data:\n",
        "        x = [word_idx[w] for w in story]\n",
        "        xq = [word_idx[w] for w in query]\n",
        "        # let's not forget that index 0 is reserved\n",
        "        y = np.zeros(len(word_idx) + 1)\n",
        "        y[word_idx[answer]] = 1\n",
        "        X.append(x)\n",
        "        Xq.append(xq)\n",
        "        Y.append(y)\n",
        "    return (pad_sequences(X, maxlen=story_maxlen),pad_sequences(Xq, maxlen=query_maxlen), np.array(Y))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcLrBqHMDVMv",
        "colab_type": "code",
        "outputId": "2b8c5451-ddea-4c82-b811-d08193a8f906",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "challenges = {\n",
        "    # QA1 with 10,000 samples\n",
        "    'single_supporting_fact_10k': 'tasks_1-20_v1-2/en-10k/qa1_single-supporting-fact_{}.txt',\n",
        "    # QA2 with 10,000 samples\n",
        "    'two_supporting_facts_10k': 'tasks_1-20_v1-2/en-10k/qa2_two-supporting-facts_{}.txt',\n",
        "}\n",
        "challenge_type = 'single_supporting_fact_10k'\n",
        "challenge = challenges[challenge_type]\n",
        "\n",
        "print('Extracting stories for the challenge:', challenge_type)\n",
        "train_stories = get_stories(tar.extractfile(challenge.format('train')))\n",
        "test_stories = get_stories(tar.extractfile(challenge.format('test')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting stories for the challenge: single_supporting_fact_10k\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/re.py:212: FutureWarning: split() requires a non-empty pattern match.\n",
            "  return _compile(pattern, flags).split(string, maxsplit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpOofkpXEGxE",
        "colab_type": "code",
        "outputId": "ac3b6382-0bff-4929-959c-66f683b2800d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_stories), len(test_stories)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYXxTnWOEMjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = set()\n",
        "for story, q, answer in train_stories + test_stories:\n",
        "    vocab |= set(story + q + [answer])\n",
        "vocab = sorted(vocab)\n",
        "\n",
        "# Reserve 0 for masking via pad_sequences\n",
        "vocab_size = len(vocab) + 1\n",
        "story_maxlen = max(map(len, (x for x, _, _ in train_stories + test_stories)))\n",
        "query_maxlen = max(map(len, (x for _, x, _ in train_stories + test_stories)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6DAVIqsFJ2c",
        "colab_type": "code",
        "outputId": "3c9251fe-aa88-418d-9b2d-635082d0de5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "story_maxlen, query_maxlen"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(68, 4)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3DfKZDb-FNM2",
        "colab_type": "code",
        "outputId": "ef5beac1-b073-41fa-bdf7-bbcfdcac3599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "print('-')\n",
        "print('Vocab size:', vocab_size, 'unique words')\n",
        "print('Story max length:', story_maxlen, 'words')\n",
        "print('Query max length:', query_maxlen, 'words')\n",
        "print('Number of training stories:', len(train_stories))\n",
        "print('Number of test stories:', len(test_stories))\n",
        "print('-')\n",
        "print('Here\\'s what a \"story\" tuple looks like (input, query, answer):')\n",
        "print(train_stories[0])\n",
        "print('-')\n",
        "print('Vectorizing the word sequences...')\n",
        "\n",
        "word_idx = dict((c, i + 1) for i, c in enumerate(vocab))\n",
        "idx_word = dict((i+1, c) for i,c in enumerate(vocab))\n",
        "inputs_train, queries_train, answers_train = vectorize_stories(train_stories,word_idx,story_maxlen,query_maxlen)\n",
        "inputs_test, queries_test, answers_test = vectorize_stories(test_stories,word_idx,story_maxlen,query_maxlen)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "Vocab size: 22 unique words\n",
            "Story max length: 68 words\n",
            "Query max length: 4 words\n",
            "Number of training stories: 10000\n",
            "Number of test stories: 1000\n",
            "-\n",
            "Here's what a \"story\" tuple looks like (input, query, answer):\n",
            "(['Mary', 'moved', 'to', 'the', 'bathroom', '.', 'John', 'went', 'to', 'the', 'hallway', '.'], ['Where', 'is', 'Mary', '?'], 'bathroom')\n",
            "-\n",
            "Vectorizing the word sequences...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4uCARTGFjip",
        "colab_type": "code",
        "outputId": "f8e98804-cf11-4f60-962e-28ce9b7c48a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "inputs_train.shape, queries_train.shape, answers_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 68), (10000, 4), (10000, 22))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcltpLbcFn5N",
        "colab_type": "code",
        "outputId": "e982201a-f5fc-4223-ebe0-f1b609d203b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "print('-')\n",
        "print('inputs: integer tensor of shape (samples, max_length)')\n",
        "print('inputs_train shape:', inputs_train.shape)\n",
        "print('inputs_test shape:', inputs_test.shape)\n",
        "print('-')\n",
        "print('queries: integer tensor of shape (samples, max_length)')\n",
        "print('queries_train shape:', queries_train.shape)\n",
        "print('queries_test shape:', queries_test.shape)\n",
        "print('-')\n",
        "print('answers: binary (1 or 0) tensor of shape (samples, vocab_size)')\n",
        "print('answers_train shape:', answers_train.shape)\n",
        "print('answers_test shape:', answers_test.shape)\n",
        "print('-')\n",
        "print('Compiling...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-\n",
            "inputs: integer tensor of shape (samples, max_length)\n",
            "inputs_train shape: (10000, 68)\n",
            "inputs_test shape: (1000, 68)\n",
            "-\n",
            "queries: integer tensor of shape (samples, max_length)\n",
            "queries_train shape: (10000, 4)\n",
            "queries_test shape: (1000, 4)\n",
            "-\n",
            "answers: binary (1 or 0) tensor of shape (samples, vocab_size)\n",
            "answers_train shape: (10000, 22)\n",
            "answers_test shape: (1000, 22)\n",
            "-\n",
            "Compiling...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsfY9Wo4GbfK",
        "colab_type": "text"
      },
      "source": [
        "##Building Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpjnmxK9Fyt3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_epochs = 100\n",
        "batch_size = 32\n",
        "lstm_size = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zJosByDzGfpC",
        "colab_type": "code",
        "outputId": "85d5f2ba-c1c5-4cfd-a9ff-803963593f4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "# placeholders\n",
        "input_sequence = Input((story_maxlen,))\n",
        "question = Input((query_maxlen,))\n",
        "\n",
        "print('Input sequence:', input_sequence)\n",
        "print('Question:', question)\n",
        "\n",
        "# encoders\n",
        "# embed the input sequence into a sequence of vectors\n",
        "input_encoder_m = Sequential()\n",
        "input_encoder_m.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=64))\n",
        "input_encoder_m.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, embedding_dim)\n",
        "\n",
        "# embed the input into a sequence of vectors of size query_maxlen\n",
        "input_encoder_c = Sequential()\n",
        "input_encoder_c.add(Embedding(input_dim=vocab_size,\n",
        "                              output_dim=query_maxlen))\n",
        "input_encoder_c.add(Dropout(0.3))\n",
        "# output: (samples, story_maxlen, query_maxlen)\n",
        "\n",
        "# embed the question into a sequence of vectors\n",
        "question_encoder = Sequential()\n",
        "question_encoder.add(Embedding(input_dim=vocab_size,\n",
        "                               output_dim=64,\n",
        "                               input_length=query_maxlen))\n",
        "question_encoder.add(Dropout(0.3))\n",
        "# output: (samples, query_maxlen, embedding_dim)\n",
        "\n",
        "# encode input sequence and questions (which are indices)\n",
        "# to sequences of dense vectors\n",
        "input_encoded_m = input_encoder_m(input_sequence)\n",
        "print('Input encoded m', input_encoded_m)\n",
        "input_encoded_c = input_encoder_c(input_sequence)\n",
        "print('Input encoded c', input_encoded_c)\n",
        "question_encoded = question_encoder(question)\n",
        "print('Question encoded', question_encoded)\n",
        "\n",
        "# compute a 'match' between the first input vector sequence\n",
        "# and the question vector sequence\n",
        "# shape: `(samples, story_maxlen, query_maxlen)\n",
        "match = merge.dot([input_encoded_m, question_encoded],axes=(2, 2))\n",
        "print(match.shape)\n",
        "match = Activation('softmax')(match)\n",
        "print('Match shape', match)\n",
        "\n",
        "# add the match matrix with the second input vector sequence\n",
        "response = merge.add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
        "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)\n",
        "print('Response shape', response)\n",
        "\n",
        "# concatenate the response vector with the question vector sequence\n",
        "answer = merge.concatenate([response, question_encoded])\n",
        "print('Answer shape', answer)\n",
        "\n",
        "#answer = LSTM(lstm_size, return_sequences=True)(answer)  # Generate tensors of shape 32\n",
        "#answer = Dropout(0.3)(answer)\n",
        "answer = LSTM(lstm_size)(answer)  # Generate tensors of shape 32\n",
        "answer = Dropout(0.3)(answer)\n",
        "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)\n",
        "# we output a probability distribution over the vocabulary\n",
        "answer = Activation('softmax')(answer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input sequence: Tensor(\"input_25:0\", shape=(?, 68), dtype=float32)\n",
            "Question: Tensor(\"input_26:0\", shape=(?, 4), dtype=float32)\n",
            "Input encoded m Tensor(\"sequential_37/dropout_37/cond/Merge:0\", shape=(?, 68, 64), dtype=float32)\n",
            "Input encoded c Tensor(\"sequential_38/dropout_38/cond/Merge:0\", shape=(?, 68, 4), dtype=float32)\n",
            "Question encoded Tensor(\"sequential_39/dropout_39/cond/Merge:0\", shape=(?, 4, 64), dtype=float32)\n",
            "(?, 68, 4)\n",
            "Match shape Tensor(\"activation_3/truediv:0\", shape=(?, 68, 4), dtype=float32)\n",
            "Response shape Tensor(\"permute_2/transpose:0\", shape=(?, 4, 68), dtype=float32)\n",
            "Answer shape Tensor(\"concatenate_2/concat:0\", shape=(?, 4, 132), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otmeEzNAGpjk",
        "colab_type": "code",
        "outputId": "8a442ce5-cda3-49e6-da5b-a2ab97834ba0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        }
      },
      "source": [
        "model = Model([input_sequence, question], answer)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_25 (InputLayer)           (None, 68)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_26 (InputLayer)           (None, 4)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_37 (Sequential)      multiple             1408        input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "sequential_39 (Sequential)      (None, 4, 64)        1408        input_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dot_5 (Dot)                     (None, 68, 4)        0           sequential_37[1][0]              \n",
            "                                                                 sequential_39[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 68, 4)        0           dot_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "sequential_38 (Sequential)      multiple             88          input_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 68, 4)        0           activation_3[0][0]               \n",
            "                                                                 sequential_38[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "permute_2 (Permute)             (None, 4, 68)        0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 4, 132)       0           permute_2[0][0]                  \n",
            "                                                                 sequential_39[1][0]              \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 64)           50432       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_40 (Dropout)            (None, 64)           0           lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 22)           1430        dropout_40[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 22)           0           dense_1[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 54,766\n",
            "Trainable params: 54,766\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBrKdZ0mMnYA",
        "colab_type": "code",
        "outputId": "8279802e-3d08-4146-e94b-9b0b73f2f501",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0817 20:10:06.203429 140243110295424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0817 20:10:06.231738 140243110295424 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaHQZ1c0M4k_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filename = 'QA_model_1.h5'\n",
        "checkpoint = ModelCheckpoint(filename, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr5CzaqlNS1h",
        "colab_type": "code",
        "outputId": "409dfe8a-6541-49fd-8a98-823fa2fbee05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit([inputs_train, queries_train], answers_train, batch_size, train_epochs,callbacks=[checkpoint],\n",
        "          validation_data=([inputs_test, queries_test], answers_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0817 20:15:19.578537 140243110295424 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 10000 samples, validate on 1000 samples\n",
            "Epoch 1/100\n",
            "10000/10000 [==============================] - 9s 902us/step - loss: 1.8989 - acc: 0.1708 - val_loss: 1.7868 - val_acc: 0.2170\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.78677, saving model to QA_model_1.h5\n",
            "Epoch 2/100\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 1.7231 - acc: 0.2495 - val_loss: 1.6053 - val_acc: 0.3500\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.78677 to 1.60528, saving model to QA_model_1.h5\n",
            "Epoch 3/100\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 1.5736 - acc: 0.3536 - val_loss: 1.5266 - val_acc: 0.3890\n",
            "\n",
            "Epoch 00003: val_loss improved from 1.60528 to 1.52665, saving model to QA_model_1.h5\n",
            "Epoch 4/100\n",
            "10000/10000 [==============================] - 4s 393us/step - loss: 1.4846 - acc: 0.4114 - val_loss: 1.4196 - val_acc: 0.4250\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.52665 to 1.41965, saving model to QA_model_1.h5\n",
            "Epoch 5/100\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 1.4237 - acc: 0.4387 - val_loss: 1.3560 - val_acc: 0.4650\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.41965 to 1.35597, saving model to QA_model_1.h5\n",
            "Epoch 6/100\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 1.3838 - acc: 0.4655 - val_loss: 1.3431 - val_acc: 0.4680\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.35597 to 1.34315, saving model to QA_model_1.h5\n",
            "Epoch 7/100\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 1.3596 - acc: 0.4727 - val_loss: 1.3213 - val_acc: 0.4890\n",
            "\n",
            "Epoch 00007: val_loss improved from 1.34315 to 1.32126, saving model to QA_model_1.h5\n",
            "Epoch 8/100\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 1.3410 - acc: 0.4764 - val_loss: 1.3112 - val_acc: 0.4880\n",
            "\n",
            "Epoch 00008: val_loss improved from 1.32126 to 1.31125, saving model to QA_model_1.h5\n",
            "Epoch 9/100\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 1.3298 - acc: 0.4806 - val_loss: 1.2863 - val_acc: 0.5070\n",
            "\n",
            "Epoch 00009: val_loss improved from 1.31125 to 1.28629, saving model to QA_model_1.h5\n",
            "Epoch 10/100\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 1.3031 - acc: 0.4878 - val_loss: 1.2881 - val_acc: 0.4820\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.28629\n",
            "Epoch 11/100\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 1.2671 - acc: 0.4983 - val_loss: 1.2078 - val_acc: 0.5280\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.28629 to 1.20782, saving model to QA_model_1.h5\n",
            "Epoch 12/100\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 1.2375 - acc: 0.5078 - val_loss: 1.1889 - val_acc: 0.5300\n",
            "\n",
            "Epoch 00012: val_loss improved from 1.20782 to 1.18894, saving model to QA_model_1.h5\n",
            "Epoch 13/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 1.2141 - acc: 0.5125 - val_loss: 1.1782 - val_acc: 0.5320\n",
            "\n",
            "Epoch 00013: val_loss improved from 1.18894 to 1.17825, saving model to QA_model_1.h5\n",
            "Epoch 14/100\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 1.2001 - acc: 0.5129 - val_loss: 1.1938 - val_acc: 0.5140\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.17825\n",
            "Epoch 15/100\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 1.1920 - acc: 0.5170 - val_loss: 1.1716 - val_acc: 0.5150\n",
            "\n",
            "Epoch 00015: val_loss improved from 1.17825 to 1.17160, saving model to QA_model_1.h5\n",
            "Epoch 16/100\n",
            "10000/10000 [==============================] - 4s 397us/step - loss: 1.1753 - acc: 0.5191 - val_loss: 1.1715 - val_acc: 0.5220\n",
            "\n",
            "Epoch 00016: val_loss improved from 1.17160 to 1.17147, saving model to QA_model_1.h5\n",
            "Epoch 17/100\n",
            "10000/10000 [==============================] - 4s 397us/step - loss: 1.1711 - acc: 0.5163 - val_loss: 1.1678 - val_acc: 0.5140\n",
            "\n",
            "Epoch 00017: val_loss improved from 1.17147 to 1.16779, saving model to QA_model_1.h5\n",
            "Epoch 18/100\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 1.1642 - acc: 0.5235 - val_loss: 1.1572 - val_acc: 0.5200\n",
            "\n",
            "Epoch 00018: val_loss improved from 1.16779 to 1.15719, saving model to QA_model_1.h5\n",
            "Epoch 19/100\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 1.1560 - acc: 0.5163 - val_loss: 1.1829 - val_acc: 0.5190\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.15719\n",
            "Epoch 20/100\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 1.1491 - acc: 0.5199 - val_loss: 1.1891 - val_acc: 0.5120\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.15719\n",
            "Epoch 21/100\n",
            "10000/10000 [==============================] - 4s 393us/step - loss: 1.1318 - acc: 0.5249 - val_loss: 1.1606 - val_acc: 0.5230\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.15719\n",
            "Epoch 22/100\n",
            "10000/10000 [==============================] - 4s 399us/step - loss: 1.1374 - acc: 0.5247 - val_loss: 1.1720 - val_acc: 0.5140\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.15719\n",
            "Epoch 23/100\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 1.1292 - acc: 0.5294 - val_loss: 1.1708 - val_acc: 0.5140\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.15719\n",
            "Epoch 24/100\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 1.1124 - acc: 0.5308 - val_loss: 1.1658 - val_acc: 0.5110\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.15719\n",
            "Epoch 25/100\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 1.1218 - acc: 0.5258 - val_loss: 1.1581 - val_acc: 0.5050\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.15719\n",
            "Epoch 26/100\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 1.1059 - acc: 0.5361 - val_loss: 1.1597 - val_acc: 0.5120\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.15719\n",
            "Epoch 27/100\n",
            "10000/10000 [==============================] - 4s 397us/step - loss: 1.1063 - acc: 0.5296 - val_loss: 1.1773 - val_acc: 0.5110\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.15719\n",
            "Epoch 28/100\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 1.0925 - acc: 0.5349 - val_loss: 1.1639 - val_acc: 0.5070\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.15719\n",
            "Epoch 29/100\n",
            "10000/10000 [==============================] - 4s 389us/step - loss: 1.0896 - acc: 0.5432 - val_loss: 1.1670 - val_acc: 0.4970\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.15719\n",
            "Epoch 30/100\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 1.0817 - acc: 0.5487 - val_loss: 1.1616 - val_acc: 0.5050\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.15719\n",
            "Epoch 31/100\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 1.0798 - acc: 0.5483 - val_loss: 1.1971 - val_acc: 0.5090\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.15719\n",
            "Epoch 32/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 1.0708 - acc: 0.5485 - val_loss: 1.2340 - val_acc: 0.4790\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.15719\n",
            "Epoch 33/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 1.0675 - acc: 0.5485 - val_loss: 1.1603 - val_acc: 0.5210\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.15719\n",
            "Epoch 34/100\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 1.0666 - acc: 0.5431 - val_loss: 1.1837 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 1.15719\n",
            "Epoch 35/100\n",
            "10000/10000 [==============================] - 4s 393us/step - loss: 1.0512 - acc: 0.5567 - val_loss: 1.1994 - val_acc: 0.4970\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 1.15719\n",
            "Epoch 36/100\n",
            "10000/10000 [==============================] - 4s 393us/step - loss: 1.0435 - acc: 0.5651 - val_loss: 1.1882 - val_acc: 0.4930\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 1.15719\n",
            "Epoch 37/100\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 1.0406 - acc: 0.5665 - val_loss: 1.1930 - val_acc: 0.5030\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 1.15719\n",
            "Epoch 38/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 1.0310 - acc: 0.5664 - val_loss: 1.2282 - val_acc: 0.5000\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 1.15719\n",
            "Epoch 39/100\n",
            "10000/10000 [==============================] - 4s 393us/step - loss: 1.0233 - acc: 0.5680 - val_loss: 1.1974 - val_acc: 0.5150\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 1.15719\n",
            "Epoch 40/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 1.0082 - acc: 0.5747 - val_loss: 1.1916 - val_acc: 0.5010\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 1.15719\n",
            "Epoch 41/100\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.9944 - acc: 0.5854 - val_loss: 1.2013 - val_acc: 0.5030\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 1.15719\n",
            "Epoch 42/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.9864 - acc: 0.5875 - val_loss: 1.1803 - val_acc: 0.5150\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 1.15719\n",
            "Epoch 43/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.9556 - acc: 0.6015 - val_loss: 1.1279 - val_acc: 0.5310\n",
            "\n",
            "Epoch 00043: val_loss improved from 1.15719 to 1.12793, saving model to QA_model_1.h5\n",
            "Epoch 44/100\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.9113 - acc: 0.6279 - val_loss: 1.0536 - val_acc: 0.5920\n",
            "\n",
            "Epoch 00044: val_loss improved from 1.12793 to 1.05359, saving model to QA_model_1.h5\n",
            "Epoch 45/100\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.8105 - acc: 0.6856 - val_loss: 0.9447 - val_acc: 0.6580\n",
            "\n",
            "Epoch 00045: val_loss improved from 1.05359 to 0.94472, saving model to QA_model_1.h5\n",
            "Epoch 46/100\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.6935 - acc: 0.7405 - val_loss: 0.8021 - val_acc: 0.7170\n",
            "\n",
            "Epoch 00046: val_loss improved from 0.94472 to 0.80206, saving model to QA_model_1.h5\n",
            "Epoch 47/100\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.6083 - acc: 0.7745 - val_loss: 0.7536 - val_acc: 0.7320\n",
            "\n",
            "Epoch 00047: val_loss improved from 0.80206 to 0.75362, saving model to QA_model_1.h5\n",
            "Epoch 48/100\n",
            "10000/10000 [==============================] - 4s 393us/step - loss: 0.5582 - acc: 0.7931 - val_loss: 0.7053 - val_acc: 0.7290\n",
            "\n",
            "Epoch 00048: val_loss improved from 0.75362 to 0.70528, saving model to QA_model_1.h5\n",
            "Epoch 49/100\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.5221 - acc: 0.8019 - val_loss: 0.6642 - val_acc: 0.7410\n",
            "\n",
            "Epoch 00049: val_loss improved from 0.70528 to 0.66416, saving model to QA_model_1.h5\n",
            "Epoch 50/100\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.4954 - acc: 0.8118 - val_loss: 0.6532 - val_acc: 0.7490\n",
            "\n",
            "Epoch 00050: val_loss improved from 0.66416 to 0.65324, saving model to QA_model_1.h5\n",
            "Epoch 51/100\n",
            "10000/10000 [==============================] - 4s 393us/step - loss: 0.4600 - acc: 0.8254 - val_loss: 0.5931 - val_acc: 0.7610\n",
            "\n",
            "Epoch 00051: val_loss improved from 0.65324 to 0.59309, saving model to QA_model_1.h5\n",
            "Epoch 52/100\n",
            "10000/10000 [==============================] - 4s 389us/step - loss: 0.4152 - acc: 0.8438 - val_loss: 0.5460 - val_acc: 0.7890\n",
            "\n",
            "Epoch 00052: val_loss improved from 0.59309 to 0.54605, saving model to QA_model_1.h5\n",
            "Epoch 53/100\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 0.3881 - acc: 0.8523 - val_loss: 0.5315 - val_acc: 0.8030\n",
            "\n",
            "Epoch 00053: val_loss improved from 0.54605 to 0.53147, saving model to QA_model_1.h5\n",
            "Epoch 54/100\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.3576 - acc: 0.8667 - val_loss: 0.4973 - val_acc: 0.8080\n",
            "\n",
            "Epoch 00054: val_loss improved from 0.53147 to 0.49734, saving model to QA_model_1.h5\n",
            "Epoch 55/100\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.3430 - acc: 0.8739 - val_loss: 0.4739 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00055: val_loss improved from 0.49734 to 0.47391, saving model to QA_model_1.h5\n",
            "Epoch 56/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.3109 - acc: 0.8877 - val_loss: 0.4982 - val_acc: 0.8080\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.47391\n",
            "Epoch 57/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.2953 - acc: 0.8901 - val_loss: 0.4626 - val_acc: 0.8260\n",
            "\n",
            "Epoch 00057: val_loss improved from 0.47391 to 0.46257, saving model to QA_model_1.h5\n",
            "Epoch 58/100\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 0.2836 - acc: 0.8939 - val_loss: 0.4549 - val_acc: 0.8340\n",
            "\n",
            "Epoch 00058: val_loss improved from 0.46257 to 0.45494, saving model to QA_model_1.h5\n",
            "Epoch 59/100\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.2712 - acc: 0.9002 - val_loss: 0.4459 - val_acc: 0.8360\n",
            "\n",
            "Epoch 00059: val_loss improved from 0.45494 to 0.44589, saving model to QA_model_1.h5\n",
            "Epoch 60/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.2530 - acc: 0.9070 - val_loss: 0.4258 - val_acc: 0.8460\n",
            "\n",
            "Epoch 00060: val_loss improved from 0.44589 to 0.42581, saving model to QA_model_1.h5\n",
            "Epoch 61/100\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.2420 - acc: 0.9091 - val_loss: 0.4316 - val_acc: 0.8490\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.42581\n",
            "Epoch 62/100\n",
            "10000/10000 [==============================] - 4s 409us/step - loss: 0.2285 - acc: 0.9156 - val_loss: 0.4441 - val_acc: 0.8430\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.42581\n",
            "Epoch 63/100\n",
            "10000/10000 [==============================] - 4s 403us/step - loss: 0.2099 - acc: 0.9241 - val_loss: 0.4318 - val_acc: 0.8460\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.42581\n",
            "Epoch 64/100\n",
            "10000/10000 [==============================] - 4s 398us/step - loss: 0.1963 - acc: 0.9242 - val_loss: 0.4225 - val_acc: 0.8500\n",
            "\n",
            "Epoch 00064: val_loss improved from 0.42581 to 0.42248, saving model to QA_model_1.h5\n",
            "Epoch 65/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.1894 - acc: 0.9325 - val_loss: 0.4974 - val_acc: 0.8400\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.42248\n",
            "Epoch 66/100\n",
            "10000/10000 [==============================] - 4s 386us/step - loss: 0.1789 - acc: 0.9339 - val_loss: 0.4374 - val_acc: 0.8600\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.42248\n",
            "Epoch 67/100\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.1660 - acc: 0.9396 - val_loss: 0.4417 - val_acc: 0.8570\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.42248\n",
            "Epoch 68/100\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.1583 - acc: 0.9462 - val_loss: 0.4450 - val_acc: 0.8610\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.42248\n",
            "Epoch 69/100\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.1460 - acc: 0.9469 - val_loss: 0.4014 - val_acc: 0.8760\n",
            "\n",
            "Epoch 00069: val_loss improved from 0.42248 to 0.40136, saving model to QA_model_1.h5\n",
            "Epoch 70/100\n",
            "10000/10000 [==============================] - 4s 393us/step - loss: 0.1381 - acc: 0.9511 - val_loss: 0.4264 - val_acc: 0.8730\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.40136\n",
            "Epoch 71/100\n",
            "10000/10000 [==============================] - 4s 388us/step - loss: 0.1238 - acc: 0.9550 - val_loss: 0.4244 - val_acc: 0.8730\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.40136\n",
            "Epoch 72/100\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.1151 - acc: 0.9593 - val_loss: 0.3916 - val_acc: 0.8870\n",
            "\n",
            "Epoch 00072: val_loss improved from 0.40136 to 0.39163, saving model to QA_model_1.h5\n",
            "Epoch 73/100\n",
            "10000/10000 [==============================] - 4s 389us/step - loss: 0.1134 - acc: 0.9605 - val_loss: 0.4270 - val_acc: 0.8690\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.39163\n",
            "Epoch 74/100\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.1008 - acc: 0.9642 - val_loss: 0.4115 - val_acc: 0.8850\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.39163\n",
            "Epoch 75/100\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.0980 - acc: 0.9649 - val_loss: 0.4273 - val_acc: 0.8830\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.39163\n",
            "Epoch 76/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.0950 - acc: 0.9664 - val_loss: 0.4085 - val_acc: 0.8810\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.39163\n",
            "Epoch 77/100\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.0881 - acc: 0.9681 - val_loss: 0.4061 - val_acc: 0.8950\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.39163\n",
            "Epoch 78/100\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.0822 - acc: 0.9706 - val_loss: 0.4366 - val_acc: 0.8860\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.39163\n",
            "Epoch 79/100\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.0795 - acc: 0.9705 - val_loss: 0.4043 - val_acc: 0.8900\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.39163\n",
            "Epoch 80/100\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.0753 - acc: 0.9743 - val_loss: 0.4827 - val_acc: 0.8870\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.39163\n",
            "Epoch 81/100\n",
            "10000/10000 [==============================] - 4s 395us/step - loss: 0.0697 - acc: 0.9746 - val_loss: 0.4060 - val_acc: 0.8920\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.39163\n",
            "Epoch 82/100\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.0734 - acc: 0.9746 - val_loss: 0.4054 - val_acc: 0.8940\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.39163\n",
            "Epoch 83/100\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.0635 - acc: 0.9787 - val_loss: 0.4289 - val_acc: 0.8970\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.39163\n",
            "Epoch 84/100\n",
            "10000/10000 [==============================] - 4s 394us/step - loss: 0.0686 - acc: 0.9770 - val_loss: 0.4139 - val_acc: 0.8960\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.39163\n",
            "Epoch 85/100\n",
            "10000/10000 [==============================] - 4s 396us/step - loss: 0.0618 - acc: 0.9793 - val_loss: 0.3964 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.39163\n",
            "Epoch 86/100\n",
            "10000/10000 [==============================] - 4s 393us/step - loss: 0.0609 - acc: 0.9776 - val_loss: 0.3761 - val_acc: 0.9070\n",
            "\n",
            "Epoch 00086: val_loss improved from 0.39163 to 0.37611, saving model to QA_model_1.h5\n",
            "Epoch 87/100\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.0520 - acc: 0.9815 - val_loss: 0.3756 - val_acc: 0.9090\n",
            "\n",
            "Epoch 00087: val_loss improved from 0.37611 to 0.37562, saving model to QA_model_1.h5\n",
            "Epoch 88/100\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.0529 - acc: 0.9823 - val_loss: 0.3816 - val_acc: 0.9070\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.37562\n",
            "Epoch 89/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.0484 - acc: 0.9842 - val_loss: 0.4319 - val_acc: 0.9040\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.37562\n",
            "Epoch 90/100\n",
            "10000/10000 [==============================] - 4s 389us/step - loss: 0.0480 - acc: 0.9853 - val_loss: 0.3943 - val_acc: 0.9110\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.37562\n",
            "Epoch 91/100\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.0457 - acc: 0.9841 - val_loss: 0.4677 - val_acc: 0.8980\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.37562\n",
            "Epoch 92/100\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.0440 - acc: 0.9854 - val_loss: 0.4199 - val_acc: 0.9070\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.37562\n",
            "Epoch 93/100\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.0393 - acc: 0.9863 - val_loss: 0.3917 - val_acc: 0.9030\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.37562\n",
            "Epoch 94/100\n",
            "10000/10000 [==============================] - 4s 387us/step - loss: 0.0417 - acc: 0.9856 - val_loss: 0.4673 - val_acc: 0.8990\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.37562\n",
            "Epoch 95/100\n",
            "10000/10000 [==============================] - 4s 385us/step - loss: 0.0411 - acc: 0.9874 - val_loss: 0.3870 - val_acc: 0.9180\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.37562\n",
            "Epoch 96/100\n",
            "10000/10000 [==============================] - 4s 391us/step - loss: 0.0418 - acc: 0.9865 - val_loss: 0.3830 - val_acc: 0.9200\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.37562\n",
            "Epoch 97/100\n",
            "10000/10000 [==============================] - 4s 390us/step - loss: 0.0378 - acc: 0.9886 - val_loss: 0.4449 - val_acc: 0.9060\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.37562\n",
            "Epoch 98/100\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.0357 - acc: 0.9878 - val_loss: 0.4045 - val_acc: 0.9150\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.37562\n",
            "Epoch 99/100\n",
            "10000/10000 [==============================] - 4s 397us/step - loss: 0.0375 - acc: 0.9883 - val_loss: 0.4416 - val_acc: 0.9080\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.37562\n",
            "Epoch 100/100\n",
            "10000/10000 [==============================] - 4s 392us/step - loss: 0.0338 - acc: 0.9873 - val_loss: 0.4190 - val_acc: 0.9100\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.37562\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8c94344080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vib4CMc6OFBK",
        "colab_type": "code",
        "outputId": "b114d657-6c87-4293-b127-07183f0f2908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "for i in range(0,10):\n",
        "        current_inp = test_stories[i]\n",
        "        current_story, current_query, current_answer = vectorize_stories([current_inp], word_idx, story_maxlen, query_maxlen)\n",
        "        current_prediction = model.predict([current_story, current_query])\n",
        "        current_prediction = idx_word[np.argmax(current_prediction)]\n",
        "        print(' '.join(current_inp[0]), ' '.join(current_inp[1]), '| Prediction:', current_prediction, '| Ground Truth:', current_inp[2])\n",
        "        print(\"-----------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "John travelled to the hallway . Mary journeyed to the bathroom . Where is John ? | Prediction: hallway | Ground Truth: hallway\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Daniel went back to the bathroom . John moved to the bedroom . Where is Mary ? | Prediction: bathroom | Ground Truth: bathroom\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Daniel went back to the bathroom . John moved to the bedroom . John went to the hallway . Sandra journeyed to the kitchen . Where is Sandra ? | Prediction: kitchen | Ground Truth: kitchen\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Daniel went back to the bathroom . John moved to the bedroom . John went to the hallway . Sandra journeyed to the kitchen . Sandra travelled to the hallway . John went to the garden . Where is Sandra ? | Prediction: hallway | Ground Truth: hallway\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Daniel went back to the bathroom . John moved to the bedroom . John went to the hallway . Sandra journeyed to the kitchen . Sandra travelled to the hallway . John went to the garden . Sandra went back to the bathroom . Sandra moved to the kitchen . Where is Sandra ? | Prediction: kitchen | Ground Truth: kitchen\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Where is Sandra ? | Prediction: hallway | Ground Truth: hallway\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Mary went to the bathroom . Sandra moved to the garden . Where is Sandra ? | Prediction: garden | Ground Truth: garden\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Mary went to the bathroom . Sandra moved to the garden . Sandra travelled to the office . Daniel journeyed to the hallway . Where is Daniel ? | Prediction: hallway | Ground Truth: hallway\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Mary went to the bathroom . Sandra moved to the garden . Sandra travelled to the office . Daniel journeyed to the hallway . Daniel journeyed to the office . John moved to the hallway . Where is Sandra ? | Prediction: office | Ground Truth: office\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Mary went to the bathroom . Sandra moved to the garden . Sandra travelled to the office . Daniel journeyed to the hallway . Daniel journeyed to the office . John moved to the hallway . John travelled to the bathroom . John journeyed to the office . Where is Daniel ? | Prediction: office | Ground Truth: office\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJtAIWUsQrTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('QA_model_1.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJshLD1CRQ5x",
        "colab_type": "code",
        "outputId": "61d497a7-871b-45ce-90f2-dd822d8a7a34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "for i in range(0,10):\n",
        "        current_inp = test_stories[i]\n",
        "        current_story, current_query, current_answer = vectorize_stories([current_inp], word_idx, story_maxlen, query_maxlen)\n",
        "        current_prediction = model.predict([current_story, current_query])\n",
        "        current_prediction = idx_word[np.argmax(current_prediction)]\n",
        "        print(' '.join(current_inp[0]), ' '.join(current_inp[1]), '| Prediction:', current_prediction, '| Ground Truth:', current_inp[2])\n",
        "        print(\"-----------------------------------------------------------------------------------------\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "John travelled to the hallway . Mary journeyed to the bathroom . Where is John ? | Prediction: hallway | Ground Truth: hallway\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Daniel went back to the bathroom . John moved to the bedroom . Where is Mary ? | Prediction: bathroom | Ground Truth: bathroom\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Daniel went back to the bathroom . John moved to the bedroom . John went to the hallway . Sandra journeyed to the kitchen . Where is Sandra ? | Prediction: kitchen | Ground Truth: kitchen\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Daniel went back to the bathroom . John moved to the bedroom . John went to the hallway . Sandra journeyed to the kitchen . Sandra travelled to the hallway . John went to the garden . Where is Sandra ? | Prediction: hallway | Ground Truth: hallway\n",
            "-----------------------------------------------------------------------------------------\n",
            "John travelled to the hallway . Mary journeyed to the bathroom . Daniel went back to the bathroom . John moved to the bedroom . John went to the hallway . Sandra journeyed to the kitchen . Sandra travelled to the hallway . John went to the garden . Sandra went back to the bathroom . Sandra moved to the kitchen . Where is Sandra ? | Prediction: kitchen | Ground Truth: kitchen\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Where is Sandra ? | Prediction: hallway | Ground Truth: hallway\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Mary went to the bathroom . Sandra moved to the garden . Where is Sandra ? | Prediction: garden | Ground Truth: garden\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Mary went to the bathroom . Sandra moved to the garden . Sandra travelled to the office . Daniel journeyed to the hallway . Where is Daniel ? | Prediction: hallway | Ground Truth: hallway\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Mary went to the bathroom . Sandra moved to the garden . Sandra travelled to the office . Daniel journeyed to the hallway . Daniel journeyed to the office . John moved to the hallway . Where is Sandra ? | Prediction: office | Ground Truth: office\n",
            "-----------------------------------------------------------------------------------------\n",
            "Sandra travelled to the kitchen . Sandra travelled to the hallway . Mary went to the bathroom . Sandra moved to the garden . Sandra travelled to the office . Daniel journeyed to the hallway . Daniel journeyed to the office . John moved to the hallway . John travelled to the bathroom . John journeyed to the office . Where is Daniel ? | Prediction: office | Ground Truth: office\n",
            "-----------------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Mzg1AjRirJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}